"""
ç½‘ç«™å‘ç°ç³»ç»Ÿ - CLIå…¥å£
"""
import argparse
import asyncio
import sys
import os
from typing import List, Optional
from website_discovery import WebsiteDiscoveryEngine

# è®¾ç½®ç¼–ç 
if sys.platform == 'win32':
    # Windows ä¸‹è®¾ç½®æ§åˆ¶å°ç¼–ç 
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except:
        pass


def parse_seed_urls(seeds_str: str) -> List[str]:
    """è§£æç§å­URLå­—ç¬¦ä¸²"""
    if not seeds_str:
        return []
    
    urls = [url.strip() for url in seeds_str.split(',')]
    return [url for url in urls if url]


def validate_config_file(config_path: str) -> bool:
    """éªŒè¯é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return False
    return True


def validate_env_file() -> bool:
    """æ£€æŸ¥ç¯å¢ƒå˜é‡æ–‡ä»¶"""
    if not os.path.exists('.env'):
        print("âš ï¸  æœªæ‰¾åˆ° .env æ–‡ä»¶ï¼Œè¯·ç¡®ä¿APIå¯†é’¥å·²é€šè¿‡å…¶ä»–æ–¹å¼è®¾ç½®")
        print("ğŸ’¡ å»ºè®®å¤åˆ¶ .env.example ä¸º .env å¹¶å¡«å†™ç›¸åº”çš„APIå¯†é’¥")
        return True  # ä¸å¼ºåˆ¶è¦æ±‚.envæ–‡ä»¶å­˜åœ¨
    return True


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='ç½‘ç«™å‘ç°ç³»ç»Ÿ - åŸºäºéœ€æ±‚æè¿°è‡ªåŠ¨å‘ç°å’Œåˆ†æç›¸å…³ç½‘ç«™',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ä½¿ç”¨ç¤ºä¾‹:
  # åŸºç¡€ç”¨æ³•
  python main.py --input "å­¦ä¹ Pythonæœºå™¨å­¦ä¹ çš„æœ€ä½³å®è·µ"
  
  # å¸¦ç§å­ç½‘ç«™
  python main.py --input "Reactå¼€å‘æ•™ç¨‹" --seeds "https://reactjs.org,https://create-react-app.dev"
  
  # è‡ªå®šä¹‰é…ç½®
  python main.py --config myconfig.yaml --input "Vue.jsæœ€ä½³å®è·µ" --max-queries 40 --output results.xlsx

æ³¨æ„äº‹é¡¹:
  1. ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–: pip install -r requirements.txt
  2. é…ç½®APIå¯†é’¥åœ¨ .env æ–‡ä»¶ä¸­
  3. æ ¹æ®éœ€è¦ä¿®æ”¹ config.yaml ä¸­çš„æä¾›å•†è®¾ç½®
        '''
    )
    
    # å¿…éœ€å‚æ•°
    parser.add_argument(
        '--input', 
        required=True,
        help='éœ€æ±‚æè¿°æ–‡æœ¬ï¼ˆå¿…éœ€ï¼‰'
    )
    
    # å¯é€‰å‚æ•°
    parser.add_argument(
        '--config', 
        default='config.yaml',
        help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: config.yamlï¼‰'
    )
    
    parser.add_argument(
        '--seeds',
        help='ç§å­ç½‘ç«™URLåˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ï¼ˆå¯é€‰ï¼‰'
    )
    
    parser.add_argument(
        '--max-queries',
        type=int,
        help='æœ€å¤§æŸ¥è¯¢æ•°é‡ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶è®¾ç½®ï¼‰'
    )
    
    parser.add_argument(
        '--max-depth',
        type=int,
        help='æœ€å¤§ä¸‹é’»æ·±åº¦ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶è®¾ç½®ï¼‰'
    )
    
    parser.add_argument(
        '--output',
        help='è¾“å‡ºExcelæ–‡ä»¶è·¯å¾„ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶è®¾ç½®ï¼‰'
    )
    
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯'
    )
    
    args = parser.parse_args()
    
    # éªŒè¯é…ç½®æ–‡ä»¶
    if not validate_config_file(args.config):
        sys.exit(1)
    
    # æ£€æŸ¥ç¯å¢ƒæ–‡ä»¶
    validate_env_file()
    
    # è§£æç§å­URLs
    seed_urls = parse_seed_urls(args.seeds) if args.seeds else []
    
    try:
        # æ‰“å°å¯åŠ¨ä¿¡æ¯
        print("=" * 60)
        print("ğŸŒ ç½‘ç«™å‘ç°ç³»ç»Ÿ - Website Discovery System")
        print("=" * 60)
        print(f"ğŸ“ éœ€æ±‚æè¿°: {args.input}")
        print(f"âš™ï¸  é…ç½®æ–‡ä»¶: {args.config}")
        if seed_urls:
            print(f"ğŸŒ ç§å­ç½‘ç«™: {len(seed_urls)} ä¸ª")
            if args.verbose:
                for url in seed_urls:
                    print(f"  - {url}")
        print(f"ğŸ” è¯¦ç»†æ¨¡å¼: {'å¼€å¯' if args.verbose else 'å…³é—­'}")
        print("=" * 60)
        print()
        
        # åˆ›å»ºå‘ç°å¼•æ“
        engine = WebsiteDiscoveryEngine(config_path=args.config)
        
        # åº”ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–
        if args.max_queries:
            engine.logic_config['max_queries'] = args.max_queries
            print(f"ğŸ”§ è¦†ç›–æœ€å¤§æŸ¥è¯¢æ•°: {args.max_queries}")
        
        if args.max_depth:
            engine.logic_config['max_depth'] = args.max_depth
            print(f"ğŸ”§ è¦†ç›–æœ€å¤§æ·±åº¦: {args.max_depth}")
        
        if args.output:
            engine.export_config['excel_path'] = args.output
            print(f"ğŸ”§ è¦†ç›–è¾“å‡ºè·¯å¾„: {args.output}")
        
        if args.max_queries or args.max_depth or args.output:
            print()
        
        # æ‰§è¡Œç½‘ç«™å‘ç°
        result = await engine.discover_websites(
            demand_text=args.input,
            seed_urls=seed_urls,
            max_depth=args.max_depth
        )
        
        # è¾“å‡ºç»“æœæ‘˜è¦
        print()
        print("=" * 60)
        print("ğŸ“Š æ‰§è¡Œæ‘˜è¦")
        print("=" * 60)
        
        if result['success']:
            print(f"âœ… ä»»åŠ¡çŠ¶æ€: æˆåŠŸ")
            print(f"â±ï¸  æ‰§è¡Œæ—¶é—´: {result['execution_time']:.2f} ç§’")
            print(f"ğŸ” ç”ŸæˆæŸ¥è¯¢: {result['queries_generated']} ä¸ª")
            print(f"ğŸŒ æœç´¢ç»“æœ: {result['search_results']} ä¸ª")
            print(f"ğŸ•·ï¸ æˆåŠŸæŠ“å–: {result['successful_crawls']} ä¸ª")
            print(f"âœ… æ¥å—ç»“æœ: {result['accepted_results']} ä¸ª")
            print(f"ğŸ“‹ æ€»è®¡ç»“æœ: {result['total_results']} ä¸ª")
            
            if 'coverage_tags' in result and result['coverage_tags']:
                print(f"ğŸ·ï¸  è¦†ç›–æ ‡ç­¾: {', '.join(result['coverage_tags'])}")
            
            if 'excel_path' in result:
                print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {result['excel_path']}")
            
            if 'csv_path' in result:
                print(f"ğŸ“„ ç®€åŒ–æŠ¥å‘Š: {result['csv_path']}")
            
            # è¯¦ç»†ä¿¡æ¯è¾“å‡º
            if args.verbose and 'contents' in result:
                print()
                print("ğŸ” é«˜åˆ†ç»“æœé¢„è§ˆ:")
                high_score_contents = [c for c in result['contents'] if c.final_score > 0.7]
                for i, content in enumerate(high_score_contents[:5], 1):
                    print(f"  {i}. [{content.final_score:.3f}] {content.title}")
                    print(f"     {content.url}")
                    print(f"     å†³ç­–: {content.decision}")
                    print()
        
        else:
            print(f"âŒ ä»»åŠ¡çŠ¶æ€: å¤±è´¥")
            print(f"â±ï¸  æ‰§è¡Œæ—¶é—´: {result['execution_time']:.2f} ç§’")
            if 'error' in result:
                print(f"âŒ é”™è¯¯ä¿¡æ¯: {result['error']}")
        
        print("=" * 60)
        
        # æ ¹æ®ç»“æœè®¾ç½®é€€å‡ºç 
        sys.exit(0 if result['success'] else 1)
        
    except KeyboardInterrupt:
        print("\nâŒ ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ç³»ç»Ÿå¼‚å¸¸: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


def run_sync():
    """åŒæ­¥è¿è¡Œå…¥å£ï¼ˆç”¨äºæ‰“åŒ…ï¼‰"""
    asyncio.run(main())


if __name__ == "__main__":
    asyncio.run(main())